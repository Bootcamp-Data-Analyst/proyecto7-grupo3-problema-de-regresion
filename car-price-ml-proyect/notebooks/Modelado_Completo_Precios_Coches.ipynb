{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ff9722"
      },
      "source": [
        "## 1. Carga de Datos y Preprocesamiento Avanzado\n",
        "\n",
        "En este primer paso, cargamos nuestro conjunto de datos limpio (`cleaned_train.csv`). Luego, aplicamos una serie de transformaciones y codificaciones avanzadas para preparar los datos para los modelos de Machine Learning. Estas acciones están basadas en los hallazgos del Análisis Exploratorio de Datos (EDA) para manejar distribuciones sesgadas, *outliers* y variables categóricas de forma efectiva. Finalmente, dividiremos los datos en conjuntos de entrenamiento y prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70154b3a",
        "outputId": "bc6d33f3-db21-43b0-99f8-704271e0e791"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats.mstats import winsorize\n",
        "!pip install category_encoders # Install the missing library\n",
        "import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib # Para guardar modelos y transformadores\n",
        "\n",
        "print(\"Librerías importadas exitosamente.\")\n",
        "\n",
        "# --- Cargar el Dataset ---\n",
        "# Cargamos el archivo CSV que contiene nuestros datos limpios de entrenamiento.\n",
        "df = pd.read_csv('/content/cleaned_train.csv')\n",
        "print(\"\\nDataset de entrenamiento cargado exitosamente. Primeras 5 filas:\")\n",
        "print(df.head(4))\n",
        "\n",
        "# --- Transformaciones Logarítmicas y Winsorización ---\n",
        "# Aplicamos logaritmo (usando log1p para manejar posibles ceros) y winsorización\n",
        "# a columnas numéricas clave para reducir el sesgo y manejar outliers.\n",
        "columns_to_transform = ['price', 'milage', 'horsepower', 'car_age']\n",
        "for col in columns_to_transform:\n",
        "    df[col] = np.log1p(df[col])\n",
        "    # La winsorización se aplica para \"tapar\" los valores extremos (outliers).\n",
        "    # Los límites (0.05, 0.05) significan que se cortan el 5% inferior y el 5% superior de los valores.\n",
        "    df[col] = winsorize(df[col], limits=(0.05, 0.05))\n",
        "print(\"\\nTransformaciones logarítmicas y winsorización aplicadas a columnas especificadas.\")\n",
        "\n",
        "# --- Manejo de Multicolinealidad ---\n",
        "# Eliminamos columnas identificadas en el EDA como redundantes o que causan multicolinealidad.\n",
        "# 'model_year' está correlacionado con 'car_age', y 'engine_size_L' con 'horsepower'/'cylinders'.\n",
        "df = df.drop(columns=['model_year', 'engine_size_L'], errors='ignore')\n",
        "print(\"\\nColumnas 'model_year' y 'engine_size_L' eliminadas para manejar multicolinealidad.\")\n",
        "\n",
        "# --- Codificación de Variables Categóricas ---\n",
        "# **Target Encoding para 'brand':** Ideal para variables con muchas categorías.\n",
        "# Reemplaza cada categoría con el promedio del valor objetivo (price) para esa categoría.\n",
        "encoder_brand = ce.TargetEncoder(cols=['brand'])\n",
        "df['brand'] = encoder_brand.fit_transform(df['brand'], df['price'])\n",
        "print(\"\\nTarget Encoding aplicado a la columna 'brand'.\")\n",
        "\n",
        "# **One-Hot Encoding para otras categóricas:** Para variables con menos categorías únicas.\n",
        "# Identificamos las columnas que aún son de tipo 'object' (texto) y aplicamos One-Hot Encoding.\n",
        "categorical_cols_ohe = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Definimos nuestra variable objetivo (Y) y nuestras características (X).\n",
        "# Y es 'price', X es el resto.\n",
        "Y = df['price']\n",
        "X = df.drop('price', axis=1)\n",
        "\n",
        "# Usamos ColumnTransformer para aplicar One-Hot Encoding solo a las columnas categóricas en X.\n",
        "# 'remainder=\\'passthrough\\'' asegura que las columnas numéricas no se vean afectadas.\n",
        "if categorical_cols_ohe:\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols_ohe)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "    X = preprocessor.fit_transform(X)\n",
        "    print(\"\\nOne-Hot Encoding aplicado a las columnas categóricas restantes en X.\")\n",
        "else:\n",
        "    print(\"\\nNo hay columnas categóricas adicionales para One-Hot Encoding.\")\n",
        "\n",
        "print(\"\\nVariables objetivo (Y) y características (X) definidas y preparadas.\")\n",
        "\n",
        "# --- División de Datos en Entrenamiento y Prueba ---\n",
        "# Dividimos los datos para entrenar el modelo con una parte y evaluarlo con datos no vistos.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(\"\\nDatos divididos en conjuntos de entrenamiento (80%) y prueba (20%).\")\n",
        "print(f\"Dimensiones de X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiones de y_train: {y_train.shape}, y_test: {y_test.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Librerías importadas exitosamente.\n",
            "\n",
            "Dataset de entrenamiento cargado exitosamente. Primeras 5 filas:\n",
            "       brand  model_year  milage      fuel_type  \\\n",
            "0       MINI        2007  213000       Gasoline   \n",
            "1    Lincoln        2002  143250       Gasoline   \n",
            "2  Chevrolet        2002  136731  E85 Flex Fuel   \n",
            "3    Genesis        2017   19500       Gasoline   \n",
            "\n",
            "                                 accident clean_title  price  car_age  \\\n",
            "0                           None reported         Yes   4200       19   \n",
            "1  At least 1 accident or damage reported         Yes   4999       24   \n",
            "2                           None reported         Yes  13900       24   \n",
            "3                           None reported         Yes  45000        9   \n",
            "\n",
            "   horsepower  engine_size_L  cylinders transmission_simple  \n",
            "0       172.0            1.6        4.0                  AT  \n",
            "1       252.0            3.9        8.0                  AT  \n",
            "2       320.0            5.3        8.0                  AT  \n",
            "3       420.0            5.0        8.0                  AT  \n",
            "\n",
            "Transformaciones logarítmicas y winsorización aplicadas a columnas especificadas.\n",
            "\n",
            "Columnas 'model_year' y 'engine_size_L' eliminadas para manejar multicolinealidad.\n",
            "\n",
            "Target Encoding aplicado a la columna 'brand'.\n",
            "\n",
            "One-Hot Encoding aplicado a las columnas categóricas restantes en X.\n",
            "\n",
            "Variables objetivo (Y) y características (X) definidas y preparadas.\n",
            "\n",
            "Datos divididos en conjuntos de entrenamiento (80%) y prueba (20%).\n",
            "Dimensiones de X_train: (150826, 20), X_test: (37707, 20)\n",
            "Dimensiones de y_train: (150826,), y_test: (37707,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3neQ2yS1b-a",
        "outputId": "2b9adc54-a4c1-4f32-834c-2263de6ee937"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 188533 entries, 0 to 188532\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   brand                188533 non-null  float64\n",
            " 1   milage               188533 non-null  float64\n",
            " 2   fuel_type            188533 non-null  object \n",
            " 3   accident             188533 non-null  object \n",
            " 4   clean_title          188533 non-null  object \n",
            " 5   price                188533 non-null  float64\n",
            " 6   car_age              188533 non-null  float64\n",
            " 7   horsepower           188533 non-null  float64\n",
            " 8   cylinders            188533 non-null  float64\n",
            " 9   transmission_simple  188533 non-null  object \n",
            "dtypes: float64(6), object(4)\n",
            "memory usage: 14.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "619f4475"
      },
      "source": [
        "## 2. Entrenamiento y Evaluación del Modelo de Regresión Lineal\n",
        "\n",
        "Comenzamos con un modelo simple de Regresión Lineal para establecer una línea base de rendimiento. Entrenaremos el modelo con los datos de entrenamiento y lo evaluaremos con los datos de prueba, utilizando métricas comunes para regresión: MAE (Error Absoluto Medio), MSE (Error Cuadrático Medio), RMSE (Raíz del Error Cuadrático Medio) y R² (Coeficiente de Determinación)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "155cca3f",
        "outputId": "dcc63702-8082-4445-c142-421dd316a0d3"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "print(\"Importando LinearRegression y métricas de evaluación.\")\n",
        "\n",
        "# Inicializamos el modelo de Regresión Lineal.\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "print(\"\\nEntrenando Modelo de Regresión Lineal...\")\n",
        "# Entrenamos el modelo con nuestros datos de entrenamiento.\n",
        "linear_model.fit(X_train, y_train)\n",
        "print(\"Modelo de Regresión Lineal entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo de Regresión Lineal ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "rmse_linear = np.sqrt(mse_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo de Regresión Lineal ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_linear:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_linear:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_linear:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_linear:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas para comparaciones futuras.\n",
        "metrics = {\n",
        "    'Linear Regression': {\n",
        "        'MAE': mae_linear,\n",
        "        'MSE': mse_linear,\n",
        "        'RMSE': rmse_linear,\n",
        "        'R2': r2_linear\n",
        "    }\n",
        "}\n",
        "print(\"Métricas de evaluación del modelo de Regresión Lineal almacenadas.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando LinearRegression y métricas de evaluación.\n",
            "\n",
            "Entrenando Modelo de Regresión Lineal...\n",
            "Modelo de Regresión Lineal entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo de Regresión Lineal ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3411\n",
            "  Mean Squared Error (MSE): 0.1977\n",
            "  Root Mean Squared Error (RMSE): 0.4446\n",
            "  R-squared (R2): 0.6462\n",
            "Métricas de evaluación del modelo de Regresión Lineal almacenadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f654e1b"
      },
      "source": [
        "## 3. Entrenamiento y Evaluación del Modelo Random Forest Regressor\n",
        "\n",
        "Ahora, implementaremos un modelo más complejo y potente: el Random Forest Regressor. Este es un modelo de conjunto que combina múltiples árboles de decisión para mejorar la precisión y controlar el sobreajuste. Entrenaremos el modelo con los mismos datos preprocesados y evaluaremos su rendimiento para compararlo con la Regresión Lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c55e8785",
        "outputId": "749ae831-1170-4a7c-eafa-252637785cb1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "print(\"Importando RandomForestRegressor.\")\n",
        "\n",
        "# Inicializamos el modelo Random Forest Regressor.\n",
        "# Usamos 'random_state' para reproducibilidad y 'n_jobs=-1' para usar todos los núcleos del CPU.\n",
        "random_forest_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"\\nEntrenando Random Forest Regressor (esto puede tomar un tiempo)...\")\n",
        "# Entrenamos el modelo con nuestros datos de entrenamiento.\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "print(\"Modelo Random Forest Regressor entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo Random Forest Regressor ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_rf = random_forest_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo Random Forest Regressor ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_rf:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_rf:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_rf:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas y mostramos la comparación entre ambos modelos.\n",
        "metrics['Random Forest'] = {\n",
        "    'MAE': mae_rf,\n",
        "    'MSE': mse_rf,\n",
        "    'RMSE': rmse_rf,\n",
        "    'R2': r2_rf\n",
        "}\n",
        "print(\"Métricas de evaluación del Random Forest almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando RandomForestRegressor.\n",
            "\n",
            "Entrenando Random Forest Regressor (esto puede tomar un tiempo)...\n",
            "Modelo Random Forest Regressor entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo Random Forest Regressor ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3282\n",
            "  Mean Squared Error (MSE): 0.1898\n",
            "  Root Mean Squared Error (RMSE): 0.4357\n",
            "  R-squared (R2): 0.6603\n",
            "Métricas de evaluación del Random Forest almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b6f3c88"
      },
      "source": [
        "## 4. Entrenamiento y Evaluación del Modelo Gradient Boosting Regressor\n",
        "\n",
        "Continuando con nuestra búsqueda del modelo más acertado, implementaremos el Gradient Boosting Regressor. Este es otro modelo de conjunto que construye árboles de decisión de forma secuencial, corrigiendo los errores de los árboles anteriores. Es conocido por su alto rendimiento y a menudo supera a otros algoritmos en tareas de regresión. Lo entrenaremos y evaluaremos para compararlo con los modelos ya analizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3cbf46",
        "outputId": "a7330655-c1e9-4f5b-9732-c53d2c592f0d"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "print(\"Importando GradientBoostingRegressor.\")\n",
        "\n",
        "# Inicializamos el modelo Gradient Boosting Regressor.\n",
        "# Usamos 'random_state' para reproducibilidad.\n",
        "# Los parámetros pueden ajustarse, pero para una primera pasada, usamos valores predeterminados razonables.\n",
        "gradient_boosting_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "print(\"\\nEntrenando Gradient Boosting Regressor (esto puede tomar un tiempo)...\")\n",
        "# Entrenamos el modelo con nuestros datos de entrenamiento.\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "print(\"Modelo Gradient Boosting Regressor entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo Gradient Boosting Regressor ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_gb = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo Gradient Boosting Regressor ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_gb:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_gb:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_gb:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_gb:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas y mostramos la comparación entre todos los modelos.\n",
        "metrics['Gradient Boosting'] = {\n",
        "    'MAE': mae_gb,\n",
        "    'MSE': mse_gb,\n",
        "    'RMSE': rmse_gb,\n",
        "    'R2': r2_gb\n",
        "}\n",
        "print(\"Métricas de evaluación del Gradient Boosting almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando GradientBoostingRegressor.\n",
            "\n",
            "Entrenando Gradient Boosting Regressor (esto puede tomar un tiempo)...\n",
            "Modelo Gradient Boosting Regressor entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo Gradient Boosting Regressor ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3147\n",
            "  Mean Squared Error (MSE): 0.1726\n",
            "  Root Mean Squared Error (RMSE): 0.4154\n",
            "  R-squared (R2): 0.6912\n",
            "Métricas de evaluación del Gradient Boosting almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n",
            "  ### Gradient Boosting ###\n",
            "    MAE: 0.3147\n",
            "    MSE: 0.1726\n",
            "    RMSE: 0.4154\n",
            "    R2: 0.6912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45fad209"
      },
      "source": [
        "### 5. Entrenamiento y Evaluación del Modelo K-Nearest Neighbors (KNN) Regressor\n",
        "\n",
        "Incluimos el modelo KNN Regressor, que predice el valor de una nueva instancia basándose en el promedio de los valores de sus k vecinos más cercanos en el espacio de características. Es un modelo simple y a menudo robusto. Lo entrenaremos y evaluaremos para compararlo con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f156a20",
        "outputId": "fee8de59-d72e-48ff-8b90-b435d04f74e0"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "print(\"Importando KNeighborsRegressor.\")\n",
        "\n",
        "# Inicializamos el modelo KNN Regressor.\n",
        "# Usamos un valor predeterminado para n_neighbors (k=5).\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "print(\"\\nEntrenando KNN Regressor (esto puede tomar un tiempo)...\")\n",
        "# Entrenamos el modelo con nuestros datos de entrenamiento.\n",
        "knn_model.fit(X_train, y_train)\n",
        "print(\"Modelo KNN Regressor entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo KNN Regressor ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "rmse_knn = np.sqrt(mse_knn)\n",
        "r2_knn = r2_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo KNN Regressor ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_knn:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_knn:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_knn:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_knn:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas y mostramos la comparación entre todos los modelos.\n",
        "metrics['KNN Regressor'] = {\n",
        "    'MAE': mae_knn,\n",
        "    'MSE': mse_knn,\n",
        "    'RMSE': rmse_knn,\n",
        "    'R2': r2_knn\n",
        "}\n",
        "print(\"Métricas de evaluación del KNN Regressor almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando KNeighborsRegressor.\n",
            "\n",
            "Entrenando KNN Regressor (esto puede tomar un tiempo)...\n",
            "Modelo KNN Regressor entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo KNN Regressor ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3364\n",
            "  Mean Squared Error (MSE): 0.1978\n",
            "  Root Mean Squared Error (RMSE): 0.4448\n",
            "  R-squared (R2): 0.6460\n",
            "Métricas de evaluación del KNN Regressor almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n",
            "  ### Gradient Boosting ###\n",
            "    MAE: 0.3147\n",
            "    MSE: 0.1726\n",
            "    RMSE: 0.4154\n",
            "    R2: 0.6912\n",
            "  ### KNN Regressor ###\n",
            "    MAE: 0.3364\n",
            "    MSE: 0.1978\n",
            "    RMSE: 0.4448\n",
            "    R2: 0.6460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f912413c"
      },
      "source": [
        "## 6. Entrenamiento y Evaluación del Modelo Support Vector Regressor (SVR)\n",
        "\n",
        "Incluiremos el Support Vector Regressor (SVR). Los SVR son modelos potentes que buscan encontrar una función que se desvíe en una cantidad máxima \\( \\epsilon \\) del objetivo para todos los puntos de entrenamiento, al mismo tiempo que es lo más plana posible. Entrenaremos y evaluaremos SVR para una comparación exhaustiva con los demás modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c0d18b",
        "outputId": "3d0a1f74-7f6c-4b3a-f8ed-a8c9d149ecc9"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "print(\"Importando SVR.\")\n",
        "\n",
        "# Inicializamos el modelo SVR.\n",
        "# SVR es computacionalmente intensivo, por lo que usaremos un subconjunto de datos\n",
        "# para una ejecución más rápida si el dataset es muy grande, o un kernel lineal simple.\n",
        "# Para una primera pasada, mantendremos los parámetros por defecto con un kernel 'rbf' y un dataset más pequeño si es necesario.\n",
        "# Sin embargo, dado el tamaño de los datos (X_train.shape), SVR con el kernel 'rbf' por defecto\n",
        "# podría tardar mucho o quedarse sin memoria. Usaremos un subconjunto de los datos.\n",
        "\n",
        "# Definimos el tamaño del subconjunto (e.g., 10% del entrenamiento) para SVR\n",
        "subset_size = 0.1 # Para pruebas rápidas, ajustar según la potencia de cálculo\n",
        "\n",
        "# Creamos un subconjunto de los datos de entrenamiento\n",
        "X_train_subset, _, y_train_subset, _ = train_test_split(\n",
        "    X_train, y_train, test_size=(1-subset_size), random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Entrenando SVR con un subconjunto de datos (tamaño: {X_train_subset.shape[0]} muestras)...\")\n",
        "\n",
        "# Inicializamos SVR. Usar kernel='linear' puede ser más rápido, o 'rbf' con un subset.\n",
        "# Ajuste C y epsilon si es necesario.\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1) # Parámetros por defecto para empezar\n",
        "\n",
        "# Entrenamos el modelo con el subconjunto de datos de entrenamiento.\n",
        "# ¡ADVERTENCIA: SVR puede ser EXTREMADAMENTE lento con grandes conjuntos de datos y el kernel rbf por defecto!\n",
        "# Si la ejecución tarda demasiado, considere reducir 'subset_size' o cambiar a kernel='linear'.\n",
        "svr_model.fit(X_train_subset, y_train_subset)\n",
        "print(\"Modelo SVR entrenado exitosamente con subconjunto de datos.\")\n",
        "\n",
        "# --- Evaluación del Modelo SVR ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba completo (X_test).\n",
        "# Nota: El modelo se entrenó con un subconjunto, pero se evalúa con el test set completo.\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo SVR ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_svr:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_svr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_svr:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_svr:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas y mostramos la comparación entre todos los modelos.\n",
        "metrics['SVR'] = {\n",
        "    'MAE': mae_svr,\n",
        "    'MSE': mse_svr,\n",
        "    'RMSE': rmse_svr,\n",
        "    'R2': r2_svr\n",
        "}\n",
        "print(\"Métricas de evaluación del SVR almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando SVR.\n",
            "Entrenando SVR con un subconjunto de datos (tamaño: 15082 muestras)...\n",
            "Modelo SVR entrenado exitosamente con subconjunto de datos.\n",
            "\n",
            "--- Evaluación del Modelo SVR ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3295\n",
            "  Mean Squared Error (MSE): 0.1873\n",
            "  Root Mean Squared Error (RMSE): 0.4328\n",
            "  R-squared (R2): 0.6648\n",
            "Métricas de evaluación del SVR almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n",
            "  ### Gradient Boosting ###\n",
            "    MAE: 0.3147\n",
            "    MSE: 0.1726\n",
            "    RMSE: 0.4154\n",
            "    R2: 0.6912\n",
            "  ### KNN Regressor ###\n",
            "    MAE: 0.3364\n",
            "    MSE: 0.1978\n",
            "    RMSE: 0.4448\n",
            "    R2: 0.6460\n",
            "  ### SVR ###\n",
            "    MAE: 0.3295\n",
            "    MSE: 0.1873\n",
            "    RMSE: 0.4328\n",
            "    R2: 0.6648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d24cc71b"
      },
      "source": [
        "## Entrenamiento y Evaluación del Modelo XGBoost Regressor\n",
        "\n",
        "### Subtask:\n",
        "Implementar un modelo XGBoost Regressor, entrenarlo con los datos de entrenamiento y evaluarlo con los datos de prueba, añadiendo sus métricas al diccionario `metrics` para una comparación completa.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0a6ef6",
        "outputId": "2ff12017-6713-4482-9f58-e0ac4677f1f2"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"Importando XGBRegressor y métricas de evaluación.\")\n",
        "\n",
        "# Inicializamos el modelo XGBoost Regressor.\n",
        "# Usamos 'random_state' para reproducibilidad y 'n_jobs=-1' para usar todos los núcleos del CPU.\n",
        "xgb_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "print(\"\\nEntrenando XGBoost Regressor (esto puede tomar un tiempo)...\")\n",
        "# Entrenamos el modelo con nuestros datos de entrenamiento.\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"Modelo XGBoost Regressor entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo XGBoost Regressor ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo XGBoost Regressor ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_xgb:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_xgb:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_xgb:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_xgb:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas y mostramos la comparación entre todos los modelos.\n",
        "metrics['XGBoost'] = {\n",
        "    'MAE': mae_xgb,\n",
        "    'MSE': mse_xgb,\n",
        "    'RMSE': rmse_xgb,\n",
        "    'R2': r2_xgb\n",
        "}\n",
        "print(\"Métricas de evaluación del XGBoost almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando XGBRegressor y métricas de evaluación.\n",
            "\n",
            "Entrenando XGBoost Regressor (esto puede tomar un tiempo)...\n",
            "Modelo XGBoost Regressor entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo XGBoost Regressor ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3075\n",
            "  Mean Squared Error (MSE): 0.1672\n",
            "  Root Mean Squared Error (RMSE): 0.4089\n",
            "  R-squared (R2): 0.7008\n",
            "Métricas de evaluación del XGBoost almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n",
            "  ### Gradient Boosting ###\n",
            "    MAE: 0.3147\n",
            "    MSE: 0.1726\n",
            "    RMSE: 0.4154\n",
            "    R2: 0.6912\n",
            "  ### KNN Regressor ###\n",
            "    MAE: 0.3364\n",
            "    MSE: 0.1978\n",
            "    RMSE: 0.4448\n",
            "    R2: 0.6460\n",
            "  ### SVR ###\n",
            "    MAE: 0.3295\n",
            "    MSE: 0.1873\n",
            "    RMSE: 0.4328\n",
            "    R2: 0.6648\n",
            "  ### XGBoost ###\n",
            "    MAE: 0.3075\n",
            "    MSE: 0.1672\n",
            "    RMSE: 0.4089\n",
            "    R2: 0.7008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ea1a65b"
      },
      "source": [
        "## Actualización de la Comparación Final de Modelos y Conclusión\n",
        "\n",
        "\n",
        "Revisar y actualizar la tabla comparativa de métricas de todos los modelos (incluyendo XGBoost) y la conclusión final para identificar el modelo más adecuado para el estudio, basándose en su rendimiento general (R2, MAE, RMSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "f82070c8",
        "outputId": "3c390650-fbea-4fd9-fc00-fba0665b8afa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"\\n--- Tabla Comparativa de Métricas de Modelos (Actualizada) ---\")\n",
        "\n",
        "# Convertimos el diccionario de métricas a un DataFrame para una mejor visualización\n",
        "metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
        "metrics_df.index.name = 'Modelo'\n",
        "\n",
        "display(metrics_df.round(4))\n",
        "\n",
        "print(\"\\n--- Conclusión sobre el Mejor Modelo (Actualizada) ---\")\n",
        "# Identificamos el modelo con el mejor R2 (el más alto) y el menor MAE/RMSE.\n",
        "best_r2_model = metrics_df['R2'].idxmax()\n",
        "best_r2_value = metrics_df['R2'].max()\n",
        "best_mae_model = metrics_df['MAE'].idxmin()\n",
        "best_mae_value = metrics_df['MAE'].min()\n",
        "\n",
        "print(f\"Basándonos en las métricas de evaluación actualizadas:\")\n",
        "print(f\"  - El modelo con el R-squared (R2) más alto es: **{best_r2_model}** con un valor de {best_r2_value:.4f}\")\n",
        "print(f\"  - El modelo con el Mean Absolute Error (MAE) más bajo es: **{best_mae_model}** con un valor de {best_mae_value:.4f}\")\n",
        "\n",
        "if best_r2_model == best_mae_model:\n",
        "    print(f\"\\nPor lo tanto, el modelo **{best_r2_model}** es el más indicado para este estudio, ya que logra el mejor balance entre la varianza explicada (R2) y el menor error absoluto medio (MAE), así como el menor error cuadrático medio (RMSE).\")\n",
        "else:\n",
        "    print(f\"\\nAunque el R2 más alto fue para {best_r2_model} y el MAE más bajo para {best_mae_model}, si consideramos el rendimiento general (R2, MAE y RMSE), el modelo **{best_mae_model}** sigue siendo la mejor elección para este estudio, ya que minimiza el error promedio.\")\n",
        "\n",
        "print(\"\\nEste modelo será utilizado para futuras predicciones y despliegue.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tabla Comparativa de Métricas de Modelos (Actualizada) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      MAE     MSE    RMSE      R2\n",
              "Modelo                                           \n",
              "Linear Regression  0.3411  0.1977  0.4446  0.6462\n",
              "Random Forest      0.3282  0.1898  0.4357  0.6603\n",
              "Gradient Boosting  0.3147  0.1726  0.4154  0.6912\n",
              "KNN Regressor      0.3364  0.1978  0.4448  0.6460\n",
              "SVR                0.3295  0.1873  0.4328  0.6648\n",
              "XGBoost            0.3075  0.1672  0.4089  0.7008"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0556f9a0-7fad-4280-a7fb-46909a755325\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Modelo</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Linear Regression</th>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.1977</td>\n",
              "      <td>0.4446</td>\n",
              "      <td>0.6462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.3282</td>\n",
              "      <td>0.1898</td>\n",
              "      <td>0.4357</td>\n",
              "      <td>0.6603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <td>0.3147</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.4154</td>\n",
              "      <td>0.6912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN Regressor</th>\n",
              "      <td>0.3364</td>\n",
              "      <td>0.1978</td>\n",
              "      <td>0.4448</td>\n",
              "      <td>0.6460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>0.3295</td>\n",
              "      <td>0.1873</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.6648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.3075</td>\n",
              "      <td>0.1672</td>\n",
              "      <td>0.4089</td>\n",
              "      <td>0.7008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0556f9a0-7fad-4280-a7fb-46909a755325')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0556f9a0-7fad-4280-a7fb-46909a755325 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0556f9a0-7fad-4280-a7fb-46909a755325');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nEste modelo ser\\u00e1 utilizado para futuras predicciones y despliegue\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Linear Regression\",\n          \"Random Forest\",\n          \"XGBoost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012828665817873144,\n        \"min\": 0.3075,\n        \"max\": 0.3411,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3411,\n          0.3282,\n          0.3075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012830432572598634,\n        \"min\": 0.1672,\n        \"max\": 0.1978,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.1977,\n          0.1898,\n          0.1672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015033917209651868,\n        \"min\": 0.4089,\n        \"max\": 0.4448,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4446,\n          0.4357,\n          0.4089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0229894251051797,\n        \"min\": 0.646,\n        \"max\": 0.7008,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6462,\n          0.6603,\n          0.7008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conclusión sobre el Mejor Modelo (Actualizada) ---\n",
            "Basándonos en las métricas de evaluación actualizadas:\n",
            "  - El modelo con el R-squared (R2) más alto es: **XGBoost** con un valor de 0.7008\n",
            "  - El modelo con el Mean Absolute Error (MAE) más bajo es: **XGBoost** con un valor de 0.3075\n",
            "\n",
            "Por lo tanto, el modelo **XGBoost** es el más indicado para este estudio, ya que logra el mejor balance entre la varianza explicada (R2) y el menor error absoluto medio (MAE), así como el menor error cuadrático medio (RMSE).\n",
            "\n",
            "Este modelo será utilizado para futuras predicciones y despliegue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df647d83"
      },
      "source": [
        "## 9. Introducción a la Validación Cruzada y Ajuste de Hiperparámetros\n",
        "\n",
        "La **validación cruzada** es una técnica esencial en el Machine Learning para evaluar de manera robusta el rendimiento de un modelo y garantizar que sus métricas de evaluación sean fiables y generalizables a datos no vistos. En lugar de dividir el conjunto de datos una única vez en entrenamiento y prueba, la validación cruzada divide los datos en múltiples subconjuntos. El modelo se entrena y evalúa repetidamente en diferentes combinaciones de estos subconjuntos. Esto ayuda a:\n",
        "\n",
        "*   **Reducir el sesgo de la evaluación**: Al promediar los resultados de múltiples iteraciones, se obtiene una estimación más precisa del rendimiento del modelo, minimizando la dependencia de una única división aleatoria de los datos.\n",
        "*   **Mitigar el sobreajuste**: Permite identificar si el modelo está aprendiendo patrones específicos del conjunto de entrenamiento en lugar de generalizar a nuevos datos, lo cual es crucial para evitar modelos que funcionan bien solo con los datos con los que fueron entrenados.\n",
        "*   **Evaluar la generalización del modelo**: Proporciona una medida más confiable de cómo se comportará el modelo en el mundo real, donde se enfrentará a datos que nunca ha visto antes.\n",
        "\n",
        "El **ajuste de hiperparámetros** es el proceso de optimizar los parámetros externos de un modelo, es decir, aquellos que no se aprenden directamente de los datos durante el entrenamiento, sino que se configuran antes de que el entrenamiento comience. Ejemplos de hiperparámetros incluyen la profundidad máxima de un árbol en un Random Forest, el número de vecinos en KNN o la tasa de aprendizaje en un Gradient Boosting. Un ajuste adecuado de estos hiperparámetros puede:\n",
        "\n",
        "*   **Mejorar significativamente el rendimiento del modelo**: Un modelo con hiperparámetros bien ajustados puede alcanzar una mayor precisión, un menor error y una mejor capacidad de generalización.\n",
        "*   **Evitar el sobreajuste o subajuste**: La elección correcta de los hiperparámetros es clave para encontrar el equilibrio perfecto entre un modelo demasiado simple (subajuste) o demasiado complejo (sobreajuste).\n",
        "*   **Optimizar el tiempo de entrenamiento y la eficiencia**: Algunos hiperparámetros pueden influir en la velocidad de entrenamiento y la cantidad de recursos computacionales necesarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1cebfda"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to implement, train, and evaluate the XGBoost Regressor model as per the instructions. This involves importing the necessary class, initializing and training the model, making predictions, calculating evaluation metrics, and updating the shared metrics dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25836b7f"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires updating the model comparison table and conclusion to include the newly trained XGBoost model. This involves converting the `metrics` dictionary into a pandas DataFrame, displaying it, identifying the best-performing model based on R2 and MAE, and then printing a revised conclusion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ccfe05"
      },
      "source": [
        "## Validación Cruzada para el Modelo Óptimo\n",
        "\n",
        "### Subtask:\n",
        "Aplicar validación cruzada (K-Fold) al modelo identificado como el más óptimo (XGBoost Regressor).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59a2c33b"
      },
      "source": [
        "**Reasoning**:\n",
        "To perform K-Fold cross-validation on the optimal XGBoost model, I need to import `KFold` and `cross_val_score` from `sklearn.model_selection`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00164d36",
        "outputId": "305f37dd-ae44-4fac-ef0e-2e9204e14238"
      },
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "print(\"Importando KFold y cross_val_score para validación cruzada.\")\n",
        "\n",
        "# Inicializamos KFold para la validación cruzada\n",
        "# n_splits define el número de \"folds\" o divisiones del conjunto de datos.\n",
        "# shuffle=True asegura que los datos se mezclan antes de dividirse, lo cual es importante si los datos tienen un orden.\n",
        "# random_state asegura la reproducibilidad de la mezcla.\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"\\nAplicando validación cruzada (K-Fold con {kf.n_splits} splits) al modelo XGBoost...\")\n",
        "\n",
        "# Calculamos las puntuaciones de R-squared utilizando cross_val_score.\n",
        "# 'scoring=\"r2\"' especifica que la métrica a optimizar/evaluar es el coeficiente de determinación R-squared.\n",
        "r2_scores_xgb = cross_val_score(xgb_model, X, Y, cv=kf, scoring='r2')\n",
        "\n",
        "print(\"Validación cruzada completada.\")\n",
        "\n",
        "# Imprimimos la puntuación media de R-squared y su desviación estándar.\n",
        "print(f\"\\n--- Resultados de la Validación Cruzada para XGBoost ---\")\n",
        "print(f\"  Media de R-squared: {r2_scores_xgb.mean():.4f}\")\n",
        "print(f\"  Desviación estándar de R-squared: {r2_scores_xgb.std():.4f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando KFold y cross_val_score para validación cruzada.\n",
            "\n",
            "Aplicando validación cruzada (K-Fold con 5 splits) al modelo XGBoost...\n",
            "Validación cruzada completada.\n",
            "\n",
            "--- Resultados de la Validación Cruzada para XGBoost ---\n",
            "  Media de R-squared: 0.7036\n",
            "  Desviación estándar de R-squared: 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7595d762"
      },
      "source": [
        "## Ajuste de Hiperparámetros con RandomizedSearchCV para el Modelo Óptimo\n",
        "\n",
        "### Subtask:\n",
        "Implementar RandomizedSearchCV para encontrar la combinación óptima de hiperparámetros para el modelo que ha sido identificado como el mejor (XGBoost).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "605c56cc"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires implementing `RandomizedSearchCV` to find the optimal hyperparameters for the XGBoost model. This involves defining a parameter distribution, initializing the search, fitting it to the training data, and then printing the best parameters and score. I will import `RandomizedSearchCV`, define the `param_dist` dictionary with common XGBoost hyperparameters and their distributions, instantiate `RandomizedSearchCV` with the `xgb_model` and specified parameters, fit it to `X_train` and `y_train`, and finally print the optimal hyperparameters and the best R2 score found.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d1dd364",
        "outputId": "9ac98d4a-52cc-4129-e536-869d1f3307e0"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "print(\"Importando RandomizedSearchCV y distribuciones para hiperparámetros.\")\n",
        "\n",
        "# --- 2. Definir un diccionario con las distribuciones de los hiperparámetros a explorar ---\n",
        "# Se definen rangos o distribuciones para los hiperparámetros clave de XGBoost.\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 1000),  # Número de árboles en el bosque\n",
        "    'learning_rate': uniform(0.01, 0.2), # Tasa de aprendizaje\n",
        "    'max_depth': randint(3, 10),         # Profundidad máxima de cada árbol\n",
        "    'subsample': uniform(0.6, 0.4),      # Fracción de muestras para entrenar cada árbol\n",
        "    'colsample_bytree': uniform(0.6, 0.4), # Fracción de características para entrenar cada árbol\n",
        "    'gamma': uniform(0, 0.5),            # Mínima pérdida de reducción para hacer una partición\n",
        "    'reg_alpha': uniform(0, 1),          # Regularización L1\n",
        "    'reg_lambda': uniform(0, 1)          # Regularización L2\n",
        "}\n",
        "\n",
        "print(\"Distribuciones de hiperparámetros definidas para XGBoost.\")\n",
        "\n",
        "# --- 3. Instanciar RandomizedSearchCV ---\n",
        "# n_iter: Número de combinaciones de hiperparámetros a probar.\n",
        "# cv: Objeto KFold para la validación cruzada.\n",
        "# scoring: Métrica a optimizar (R-squared en este caso).\n",
        "# random_state: Para reproducibilidad.\n",
        "# n_jobs: Para usar todos los núcleos del CPU disponibles.\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50, # Se pueden ajustar las iteraciones para mayor exhaustividad o menor tiempo\n",
        "    cv=kf, # Utilizando el objeto KFold ya definido\n",
        "    scoring='r2',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV inicializado.\")\n",
        "\n",
        "# --- 4. Ajustar (fit) el objeto RandomizedSearchCV a los datos de entrenamiento ---\n",
        "print(\"\\nIniciando búsqueda aleatoria de hiperparámetros para XGBoost (esto puede tomar un tiempo)...\")\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Búsqueda aleatoria de hiperparámetros completada.\")\n",
        "\n",
        "# --- 5. Imprimir los mejores hiperparámetros y la mejor puntuación ---\n",
        "print(\"\\n--- Mejores Hiperparámetros encontrados para XGBoost ---\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"\\n--- Mejor puntuación R-squared obtenida (validación cruzada): {random_search.best_score_:.4f} ---\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importando RandomizedSearchCV y distribuciones para hiperparámetros.\n",
            "Distribuciones de hiperparámetros definidas para XGBoost.\n",
            "RandomizedSearchCV inicializado.\n",
            "\n",
            "Iniciando búsqueda aleatoria de hiperparámetros para XGBoost (esto puede tomar un tiempo)...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Búsqueda aleatoria de hiperparámetros completada.\n",
            "\n",
            "--- Mejores Hiperparámetros encontrados para XGBoost ---\n",
            "{'colsample_bytree': np.float64(0.6550083776583973), 'gamma': np.float64(0.17053317552512925), 'learning_rate': np.float64(0.032694704248117816), 'max_depth': 9, 'n_estimators': 514, 'reg_alpha': np.float64(0.877339353380981), 'reg_lambda': np.float64(0.2579416277151556), 'subsample': np.float64(0.8639936184136716)}\n",
            "\n",
            "--- Mejor puntuación R-squared obtenida (validación cruzada): 0.7075 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44b69150"
      },
      "source": [
        "## Evaluación del Modelo Óptimo con Hiperparámetros Ajustados\n",
        "\n",
        "### Subtask:\n",
        "Una vez encontrados los mejores hiperparámetros, se entrenará un nuevo modelo (el óptimo) con estos parámetros finales. Este modelo se evaluará en el conjunto de prueba (X_test, y_test) para obtener sus métricas (MAE, MSE, RMSE, R²), las cuales se añadirán al diccionario metrics para una comparación final y actualizada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d544121"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires training a new XGBoost model with the optimal hyperparameters found by `RandomizedSearchCV`, evaluating it, and updating the `metrics` dictionary. I will initialize `XGBRegressor` with `best_params_`, train it on `X_train` and `y_train`, predict on `X_test`, calculate evaluation metrics, add them to `metrics`, and then print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61a40361",
        "outputId": "69a2d4ea-1e7b-49d3-cf3f-231cdfbc8770"
      },
      "source": [
        "print(\"Evaluando el modelo XGBoost óptimo con los hiperparámetros ajustados...\")\n",
        "\n",
        "# Obtener los mejores hiperparámetros del RandomizedSearchCV\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Inicializar un nuevo modelo XGBoost con los hiperparámetros óptimos\n",
        "# Aseguramos que n_jobs esté presente para usar todos los núcleos\n",
        "optimized_xgb_model = XGBRegressor(random_state=42, n_jobs=-1, **best_params)\n",
        "\n",
        "print(\"\\nEntrenando el modelo XGBoost optimizado...\")\n",
        "# Entrenar el modelo optimizado\n",
        "optimized_xgb_model.fit(X_train, y_train)\n",
        "print(\"Modelo XGBoost optimizado entrenado exitosamente.\")\n",
        "\n",
        "# --- Evaluación del Modelo XGBoost Optimizado ---\n",
        "# Hacemos predicciones sobre el conjunto de prueba.\n",
        "y_pred_optimized_xgb = optimized_xgb_model.predict(X_test)\n",
        "\n",
        "# Calculamos las métricas de evaluación.\n",
        "mae_optimized_xgb = mean_absolute_error(y_test, y_pred_optimized_xgb)\n",
        "mse_optimized_xgb = mean_squared_error(y_test, y_pred_optimized_xgb)\n",
        "rmse_optimized_xgb = np.sqrt(mse_optimized_xgb)\n",
        "r2_optimized_xgb = r2_score(y_test, y_pred_optimized_xgb)\n",
        "\n",
        "print(f\"\\n--- Evaluación del Modelo XGBoost Optimizado ---\\n\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_optimized_xgb:.4f}\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse_optimized_xgb:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse_optimized_xgb:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2_optimized_xgb:.4f}\")\n",
        "\n",
        "# Almacenamos las métricas en el diccionario `metrics`\n",
        "metrics['XGBoost Optimized'] = {\n",
        "    'MAE': mae_optimized_xgb,\n",
        "    'MSE': mse_optimized_xgb,\n",
        "    'RMSE': rmse_optimized_xgb,\n",
        "    'R2': r2_optimized_xgb\n",
        "}\n",
        "print(\"Métricas de evaluación del XGBoost optimizado almacenadas.\")\n",
        "\n",
        "print(\"\\n--- Comparación Final de Métricas de Modelos (Actualizada) ---\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"  ### {model_name} ###\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"    {metric_name}: {value:.4f}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando el modelo XGBoost óptimo con los hiperparámetros ajustados...\n",
            "\n",
            "Entrenando el modelo XGBoost optimizado...\n",
            "Modelo XGBoost optimizado entrenado exitosamente.\n",
            "\n",
            "--- Evaluación del Modelo XGBoost Optimizado ---\n",
            "\n",
            "  Mean Absolute Error (MAE): 0.3056\n",
            "  Mean Squared Error (MSE): 0.1648\n",
            "  Root Mean Squared Error (RMSE): 0.4060\n",
            "  R-squared (R2): 0.7050\n",
            "Métricas de evaluación del XGBoost optimizado almacenadas.\n",
            "\n",
            "--- Comparación Final de Métricas de Modelos (Actualizada) ---\n",
            "  ### Linear Regression ###\n",
            "    MAE: 0.3411\n",
            "    MSE: 0.1977\n",
            "    RMSE: 0.4446\n",
            "    R2: 0.6462\n",
            "  ### Random Forest ###\n",
            "    MAE: 0.3282\n",
            "    MSE: 0.1898\n",
            "    RMSE: 0.4357\n",
            "    R2: 0.6603\n",
            "  ### Gradient Boosting ###\n",
            "    MAE: 0.3147\n",
            "    MSE: 0.1726\n",
            "    RMSE: 0.4154\n",
            "    R2: 0.6912\n",
            "  ### KNN Regressor ###\n",
            "    MAE: 0.3364\n",
            "    MSE: 0.1978\n",
            "    RMSE: 0.4448\n",
            "    R2: 0.6460\n",
            "  ### SVR ###\n",
            "    MAE: 0.3295\n",
            "    MSE: 0.1873\n",
            "    RMSE: 0.4328\n",
            "    R2: 0.6648\n",
            "  ### XGBoost ###\n",
            "    MAE: 0.3075\n",
            "    MSE: 0.1672\n",
            "    RMSE: 0.4089\n",
            "    R2: 0.7008\n",
            "  ### XGBoost Optimized ###\n",
            "    MAE: 0.3056\n",
            "    MSE: 0.1648\n",
            "    RMSE: 0.4060\n",
            "    R2: 0.7050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f3faca6"
      },
      "source": [
        "## Predicción de Precios en Datos de Prueba con el Modelo Óptimo Final\n",
        "\n",
        "### Subtask:\n",
        "Utilizar el modelo más óptimo y ajustado (XGBoost optimizado) para predecir precios en el conjunto de datos `cleaned_test.csv`. Se asegurará que todos los pasos de preprocesamiento sean consistentes y se revertirán las transformaciones logarítmicas para mostrar los precios en su escala original.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bef09adf"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires using the optimized XGBoost model to predict prices on the `cleaned_test.csv` dataset. This involves applying the exact same preprocessing steps to the test data as were applied to the training data, making predictions, and then reverting the log transformation to get the original price scale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6253cc23",
        "outputId": "cf0f55b8-d389-403f-ca03-7b537d8a1c30"
      },
      "source": [
        "print(\"Cargando y preprocesando el archivo cleaned_test.csv para predicciones...\")\n",
        "\n",
        "# --- 1. Cargar el Dataset de Prueba --- (Mantendremos el df_test original para comparación)\n",
        "df_original_test = pd.read_csv('/content/cleaned_test.csv')\n",
        "df_test = df_original_test.copy() # Creamos una copia para las transformaciones\n",
        "print(\"\\nDataset de prueba cargado exitosamente. Primeras 5 filas (original):\")\n",
        "print(df_test.head())\n",
        "\n",
        "# --- 2. Aplicar las Mismas Transformaciones del Entrenamiento ---\n",
        "# Columnas para transformación logarítmica y winsorización.\n",
        "feature_columns_to_transform = ['milage', 'horsepower', 'car_age']\n",
        "\n",
        "for col in feature_columns_to_transform:\n",
        "    df_test[col] = np.log1p(df_test[col])\n",
        "    df_test[col] = winsorize(df_test[col], limits=(0.05, 0.05)) # Aplicamos la misma winsorización.\n",
        "print(\"\\nLog transformación y winsorización aplicadas a las características del set de prueba.\")\n",
        "\n",
        "# --- 3. Eliminar columnas para consistencia ---\n",
        "df_test = df_test.drop(columns=['model_year', 'engine_size_L'], errors='ignore')\n",
        "print(\"Columnas 'model_year' y 'engine_size_L' eliminadas del set de prueba.\")\n",
        "\n",
        "# --- 4. Aplicar Target Encoding a 'brand' ---\n",
        "df_test['brand'] = encoder_brand.transform(df_test['brand'])\n",
        "print(\"Target Encoding aplicado a la columna 'brand' del set de prueba (usando el encoder entrenado).\")\n",
        "\n",
        "# --- 5. Preparar las características para la predicción (X_new_test) ---\n",
        "# Si 'price' está en el set de prueba (que no debería para predicción), la eliminamos.\n",
        "if 'price' in df_test.columns:\n",
        "    X_new_test = df_test.drop('price', axis=1)\n",
        "else:\n",
        "    X_new_test = df_test.copy()\n",
        "\n",
        "# --- 6. Aplicar One-Hot Encoding ---\n",
        "X_new_test_processed = preprocessor.transform(X_new_test)\n",
        "print(\"One-Hot Encoding aplicado a las columnas categóricas restantes del set de prueba (usando el preprocessor entrenado).\")\n",
        "\n",
        "# --- 7. Realizar Predicciones con el Modelo Optimizado (XGBoost) ---\n",
        "y_pred_new_test_log = optimized_xgb_model.predict(X_new_test_processed)\n",
        "print(\"\\nPredicciones generadas en la escala logarítmica con el modelo XGBoost optimizado.\")\n",
        "\n",
        "# --- 8. Revertir Transformación Logarítmica ---\n",
        "# Convertimos las predicciones de nuevo a la escala de precio original (deshacemos log1p).\n",
        "y_pred_new_test = np.expm1(y_pred_new_test_log)\n",
        "print(\"Predicciones convertidas a la escala de precio original.\")\n",
        "\n",
        "# --- 9. Añadir predicciones y marca original al DataFrame de prueba ---\n",
        "df_test['predicted_price'] = y_pred_new_test\n",
        "df_test['original_brand'] = df_original_test['brand'] # Añadimos la columna de marca original\n",
        "\n",
        "# --- 10. Imprimir las primeras 10 predicciones ---\n",
        "print(\"\\n--- Primeras 10 Predicciones de Precios en el Conjunto de Prueba (con marca original) ---\")\n",
        "print(df_test[['original_brand', 'milage', 'car_age', 'predicted_price']].head(10))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando y preprocesando el archivo cleaned_test.csv para predicciones...\n",
            "\n",
            "Dataset de prueba cargado exitosamente. Primeras 5 filas (original):\n",
            "  brand  model_year  milage fuel_type       accident clean_title  car_age  \\\n",
            "0  Land        2015   98000  Gasoline  None reported         Yes       11   \n",
            "1  Land        2020    9142    Hybrid  None reported         Yes        6   \n",
            "2  Ford        2022   28121  Gasoline  None reported     Unknown        4   \n",
            "3  Audi        2016   61258  Gasoline  None reported     Unknown       10   \n",
            "4  Audi        2018   59000  Gasoline  None reported         Yes        8   \n",
            "\n",
            "   horsepower  engine_size_L  cylinders transmission_simple  \n",
            "0       240.0            2.0        4.0                  AT  \n",
            "1       395.0            3.0        6.0                  AT  \n",
            "2       328.0            3.5        6.0                  AT  \n",
            "3       328.0            3.5        6.0                  AT  \n",
            "4       252.0            2.0        4.0                  AT  \n",
            "\n",
            "Log transformación y winsorización aplicadas a las características del set de prueba.\n",
            "Columnas 'model_year' y 'engine_size_L' eliminadas del set de prueba.\n",
            "Target Encoding aplicado a la columna 'brand' del set de prueba (usando el encoder entrenado).\n",
            "One-Hot Encoding aplicado a las columnas categóricas restantes del set de prueba (usando el preprocessor entrenado).\n",
            "\n",
            "Predicciones generadas en la escala logarítmica con el modelo XGBoost optimizado.\n",
            "Predicciones convertidas a la escala de precio original.\n",
            "\n",
            "--- Primeras 10 Predicciones de Precios en el Conjunto de Prueba (con marca original) ---\n",
            "  original_brand     milage   car_age  predicted_price\n",
            "0           Land  11.492733  2.484907     16822.462891\n",
            "1           Land   9.120744  1.945910     61904.851562\n",
            "2           Ford  10.244307  1.609438     53722.218750\n",
            "3           Audi  11.022866  2.397895     25424.816406\n",
            "4           Audi  10.985310  2.197225     29219.064453\n",
            "5      Chevrolet  11.508164  2.639057     17499.173828\n",
            "6          Lexus  11.995358  2.944439     10131.960938\n",
            "7      Chevrolet  10.601846  2.079442     37807.847656\n",
            "8  Mercedes-Benz   8.936035  2.397895     57781.226562\n",
            "9        Genesis  11.055656  2.302585     26520.800781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24bcec0b"
      },
      "source": [
        "## Guardar el Modelo Óptimo Final y Preprocesadores para Despliegue en Streamlit\n",
        "\n",
        "### Subtask:\n",
        "Guardar el modelo final y óptimo (después de la validación cruzada y el ajuste de hiperparámetros), junto con los preprocesadores (`encoder_brand` y `preprocessor`), para su futuro despliegue en Streamlit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3d0ecc7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires saving the final optimized model and the preprocessors for deployment. I will use joblib to save the `optimized_xgb_model`, `encoder_brand`, and `preprocessor`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c89b87f",
        "outputId": "6fbab49d-9acb-4c41-a927-2345630d3d20"
      },
      "source": [
        "import joblib\n",
        "\n",
        "print(\"Guardando el modelo y los preprocesadores entrenados...\")\n",
        "\n",
        "# Guardamos el modelo XGBoost optimizado (ya que fue el mejor).\n",
        "joblib.dump(optimized_xgb_model, 'optimized_xgb_model.pkl')\n",
        "print(\"  Modelo XGBoost optimizado guardado como 'optimized_xgb_model.pkl'.\")\n",
        "\n",
        "# Guardamos el Target Encoder para la variable 'brand'.\n",
        "joblib.dump(encoder_brand, 'encoder_brand.pkl')\n",
        "print(\"  Target Encoder para 'brand' guardado como 'encoder_brand.pkl'.\")\n",
        "\n",
        "# Guardamos el ColumnTransformer para el One-Hot Encoding de otras variables categóricas.\n",
        "joblib.dump(preprocessor, 'column_transformer_preprocessor.pkl')\n",
        "print(\"  ColumnTransformer para One-Hot Encoding guardado como 'column_transformer_preprocessor.pkl'.\")\n",
        "\n",
        "print(\"\\nTodos los componentes necesarios para el despliegue en Streamlit han sido guardados exitosamente.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardando el modelo y los preprocesadores entrenados...\n",
            "  Modelo XGBoost optimizado guardado como 'optimized_xgb_model.pkl'.\n",
            "  Target Encoder para 'brand' guardado como 'encoder_brand.pkl'.\n",
            "  ColumnTransformer para One-Hot Encoding guardado como 'column_transformer_preprocessor.pkl'.\n",
            "\n",
            "Todos los componentes necesarios para el despliegue en Streamlit han sido guardados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1b4877"
      },
      "source": [
        "## Conclusión Final y Próximos Pasos\n",
        "\n",
        "Hemos completado un proceso exhaustivo de modelado predictivo, desde el preprocesamiento avanzado hasta la interpretación y optimización del modelo, y la predicción en datos nuevos.\n",
        "\n",
        "Inicialmente, evaluamos varios modelos de regresión: Regresión Lineal, Random Forest Regressor, Gradient Boosting Regressor, K-Nearest Neighbors Regressor (KNN) y Support Vector Regressor (SVR). En una primera fase, el **Gradient Boosting Regressor** se destacó por su rendimiento superior.\n",
        "\n",
        "Posteriormente, introdujimos y evaluamos el **XGBoost Regressor**, el cual mostró un rendimiento aún mejor que los modelos anteriores, convirtiéndose en el candidato óptimo para una optimización más profunda.\n",
        "\n",
        "Para asegurar la robustez de nuestra evaluación y mejorar aún más el rendimiento, aplicamos **validación cruzada (K-Fold)** y **ajuste de hiperparámetros utilizando RandomizedSearchCV** al modelo XGBoost. Este proceso nos permitió encontrar la configuración de parámetros que maximiza la capacidad predictiva del modelo.\n",
        "\n",
        "El **modelo XGBoost optimizado** demostró ser el más adecuado para este problema, alcanzando las siguientes métricas finales:\n",
        "  - **Mean Absolute Error (MAE): 0.3056**\n",
        "  - **Mean Squared Error (MSE): 0.1648**\n",
        "  - **Root Mean Squared Error (RMSE): 0.4060**\n",
        "  - **R-squared (R2): 0.7050**\n",
        "\n",
        "Estos resultados confirman que el XGBoost optimizado es nuestro modelo final óptimo, logrando el mejor balance entre la varianza explicada (R2) y el menor error absoluto medio (MAE). Todos los componentes clave del flujo de trabajo (el modelo XGBoost optimizado, el encoder de Target Encoding para 'brand' y el ColumnTransformer para One-Hot Encoding) han sido guardados. Esto los deja listos para ser integrados en tu aplicación de Streamlit.\n",
        "\n",
        "El siguiente paso será diseñar y desarrollar la interfaz de usuario en Streamlit para permitir a los usuarios introducir datos y obtener predicciones de precios de coches en tiempo real, utilizando el modelo y los preprocesadores guardados."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8DmxDpDUhJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}